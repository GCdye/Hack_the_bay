{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building - VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source for how to use statsmodels VAR model for data showing seasonality: https://stats.stackexchange.com/questions/253355/time-series-data-with-seasonality-using-var#:~:text=2%20Answers&text=VAR%20models%20are%20routinely%20used,GDP%20or%20unemployment)%20are%20seasonal.\n",
    "Source for code: Mahdi Shadkham-Farokhi - General Assembly - Time Series analysis lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import six\n",
    "import joblib\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/WQ_FINAL_with_Parameters.csv\", parse_dates=['Date_Time'], index_col=['Date_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "we can separate data\n",
    "- by HUCNAME (use avarage parameter values by day)\n",
    "- by SampleDepth (aggregate data for depths where not many sampling points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate Data by HUCNAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the amount of datapoints available for each HUC station\n",
    "# df[['HUCNAME_']].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(by='SampleDepth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlet = df.loc[(df['HUCNAME_'] == 'Outlet Potomac River')][['SampleDepth', 'Parameter_CHLA', 'Parameter_DO',\n",
    "#        'Parameter_NH4F', 'Parameter_NO3F', 'Parameter_PH', 'Parameter_PO4F',\n",
    "#        'Parameter_SALINITY', 'Parameter_SECCHI', 'Parameter_TALK',\n",
    "#        'Parameter_TDS', 'Parameter_TKNW', 'Parameter_TN', 'Parameter_TP',\n",
    "#        'Parameter_TSS', 'Parameter_TURB_NTU', 'Parameter_WTEMP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 8))\n",
    "# outlet.groupby(by='SampleDepth')['Parameter_CHLA'].count().sort_values(ascending=False).plot(kind='bar');\n",
    "# plt.ylim(bottom=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select parameter columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_columns(dataframe):\n",
    "    \"\"\"\n",
    "    function \n",
    "    selects parameter columns\n",
    "    returns dataframe of parameters\n",
    "    \"\"\"\n",
    "    param_cols = []\n",
    "    for col in dataframe.columns:\n",
    "        if 'Parameter' in col:\n",
    "            param_cols.append(col)\n",
    "#     print(param_cols)\n",
    "    return dataframe[param_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataset with only the parameter columns\n",
    "params = parameter_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe by date_time index \n",
    "params.sort_index(ascending = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visually quick_inspect data\n",
    "\n",
    "params.plot(legend='right', xlim=('2005-07-01', '2022-12-01'), figsize=(20, 6));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** At first glance, it seems that \n",
    "- there was an uncharacteristic upsurge of TSS (Total Suspended Solids) in 2019 (or beginning of 2020) - wonder what could have happened\n",
    "- level of TDS (Total Dissolved Solids flattened out after 2014)\n",
    "- water tempreture seems seasonal - as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahdi's code\n",
    "\n",
    "fig, axes = plt.subplots(figsize = (15, 20), ncols=2, nrows=8)\n",
    "\n",
    "# flatten axes \n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(16):\n",
    "    ax = axes[i]\n",
    "    col_name = params.columns[i]\n",
    "    ax.set_title(col_name)\n",
    "    ax.set_xlabel(\"Date_Time\")\n",
    "    ax.set_ylabel(col_name)\n",
    "    params[col_name].plot(ax = ax)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample data to weekly periods\n",
    "weekly_params = params.resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_params = params.resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_params.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_params.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (15, 20), ncols=2, nrows=8)\n",
    "\n",
    "# flatten axes \n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(16):\n",
    "    ax = axes[i]\n",
    "    col_name = weekly_params.columns[i]\n",
    "    ax.set_title(col_name)\n",
    "    ax.set_xlabel(\"Date_Time\")\n",
    "    ax.set_ylabel(col_name)\n",
    "    weekly_params[col_name].plot(ax = ax)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot daily data\n",
    "fig, axes = plt.subplots(figsize = (15, 20), ncols=2, nrows=8)\n",
    "\n",
    "# flatten axes \n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(16):\n",
    "    ax = axes[i]\n",
    "    col_name = daily_params.columns[i]\n",
    "    ax.set_title(col_name)\n",
    "    ax.set_xlabel(\"Date_Time\")\n",
    "    ax.set_ylabel(col_name)\n",
    "    daily_params[col_name].plot(ax = ax)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick line plot\n",
    "# for col in weekly_params.columns:\n",
    "#     plt.figure(figsize=(20, 4))\n",
    "#     plt.title(col)\n",
    "#     weekly_params[col].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seasonal Decomposition of variables that show seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_params = weekly_params.dropna()\n",
    "weekly_params.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# weekly_trunc = params.loc[params.index > '2017-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to plot seasonal decomposition\n",
    "\n",
    "def decompose(parameter, model, period):\n",
    "    \"\"\"\n",
    "    function\n",
    "    takes parameter as dataframe, model, period\n",
    "    plot seasonal decomposition\n",
    "    \"\"\"\n",
    "    decomp = seasonal_decompose(parameter, model=model, period=period)\n",
    "    decomp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot seasonal decomposition for each parameter in truncated dataframe (df) - weekly aggregate\n",
    "# model = additive\n",
    "# period = 52 (weekly seasonality) \n",
    "\n",
    "cols = weekly_params.columns\n",
    "for col in cols:\n",
    "    decompose(parameter=weekly_params[col],\n",
    "              model='additive',\n",
    "              period=52)\n",
    "    \n",
    "    # seasonality looks yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the standard deviation to eyeball whether seasonality is significant in any of the variables\n",
    "\n",
    "weekly_params.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot seasonal decomposition for each parameter in truncated dataframe (df) - daily aggregate\n",
    "# model = additive\n",
    "# period = 7 (daily periods) \n",
    "\n",
    "cols = daily_params.columns\n",
    "for col in cols:\n",
    "    decompose(parameter=daily_params[col],\n",
    "              model='additive',\n",
    "              period=52)\n",
    "    \n",
    "    # seasonality looks yearly daily_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autocorrelation Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot autocorrelation and partial autocorrelation\n",
    "\n",
    "def autocorrelation(df, lags):\n",
    "    plot_acf(df, lags=lags);\n",
    "    plot_pacf(df, lags=lags);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Clorophyll - weekly aggregates\n",
    "print(cols[0])\n",
    "autocorrelation(weekly_params[cols[0]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clorophyll seems to have seasonality - roughly 1 year periods, no trend (the small lag values have relatively small, albiet positive, autocorrelation values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Dissolved Oxygen - weekly aggregates\n",
    "print(cols[1])\n",
    "autocorrelation(weekly_params[cols[1]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dissolved oxygen - shows seasonality - roughly 1 year periods.\n",
    "Trend: follows changes of physical seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Ammonia nitrogen - weekly aggregates\n",
    "print(cols[2])\n",
    "autocorrelation(weekly_params[cols[2]], lags=70);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ammonia nitrogen - shows seasonal tendency - around 40 weeks, no trend(?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Nitrate Nitrogen - weekly aggregates\n",
    "print(cols[3])\n",
    "autocorrelation(weekly_params[cols[3]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nitrate Nitrogen - shows seasonal changes (less than 1 year). No trend(?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for PH level (corrected for temperature) - weekly aggregates\n",
    "print(cols[4])\n",
    "autocorrelation(weekly_params[cols[4]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PH level (corrected for temperature) - no seasonality, no trend. Lag 12 and 38 are the most important predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Orthophosphate Phosphorus - weekly aggregates\n",
    "print(cols[5])\n",
    "autocorrelation(weekly_params[cols[5]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orthophosphate Phosphorus - no seasonality, no trend. Lag 45 is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Salinity - weekly aggregates\n",
    "print(cols[6])\n",
    "autocorrelation(weekly_params[cols[6]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salinity - not seasonal, no trend, lags 1, 3, and 4 seem important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for SECCHI DEPTH - weekly aggregates\n",
    "print(cols[7])\n",
    "autocorrelation(weekly_params[cols[7]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secchi depth - no seasonality, no trend, lags 4, 32, 36 and 45 seem important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Total Alkalinity - weekly aggregates\n",
    "print(cols[8])\n",
    "autocorrelation(weekly_params[cols[8]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Alkalinity - no seasonality (?), no trend, lag 2, 3, 4 and 47 seem important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Total Dissolved Solids - weekly aggregates\n",
    "print(cols[9])\n",
    "autocorrelation(weekly_params[cols[9]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Dissolved Solids - no seasonality, no trend, lag 1 and 43 seems important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Total Kjedahl Nitrogen - weekly aggregates\n",
    "print(cols[10])\n",
    "autocorrelation(weekly_params[cols[10]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Kjedahl Nitrogen - no seasonality, no trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Total Nitrogen - weekly aggregates\n",
    "print(cols[11])\n",
    "autocorrelation(weekly_params[cols[11]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Nitrogen - shows seasonality (?), no trend, roughly yearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Total Phosphorus - weekly aggregates\n",
    "print(cols[12])\n",
    "autocorrelation(weekly_params[cols[12]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Phosphorus - no seasonality, not trend, important lags: 14, 51."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Total Suspended Solids - weekly aggregates\n",
    "print(cols[13])\n",
    "autocorrelation(weekly_params[cols[13]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total suspended solids - no trend, no seasonality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Turbidity - Nephelometric Method - weekly aggregates\n",
    "print(cols[14])\n",
    "autocorrelation(weekly_params[cols[14]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Water Clarity (turbidity, nephelometric method - used to test post filtration water clarity) - no seasonality, no trend. Important lags: 1, 5, 32, 38. <br>\n",
    "source: https://www.hach.com/turbidity-article-turbidity101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot autocorrelation for Water Temperature - weekly aggregates\n",
    "print(cols[15])\n",
    "autocorrelation(weekly_params[cols[15]], lags=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Water Temperature - shows seasonality (yearly), trend follows sine wave. Important lags: 1, 2, 5.\n",
    "\n",
    "**Drop Parameter_TURB_NTU - and used only SECCHI as a metric for turbidity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df = weekly_params.drop(columns=['Parameter_TURB_NTU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = daily_params.drop(columns=['Parameter_TURB_NTU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the data is in daily increments\n",
    "\n",
    "daily_df.resample('D').mean().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_df = weekly_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Establish stationarity**<br>\n",
    "Daily Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct Augmented Dicky-Fuller test - print test statistic and p-value\n",
    "\n",
    "def interpret_adftest(target_column):\n",
    "    '''Returns the Test Statistic and p-value for Augmented Dickey-Fuller test on given target column'''\n",
    "    test = adfuller(target_column)\n",
    "    output = pd.Series(test[0:2], index=['Test Statistic','p-value'])\n",
    "    return output\n",
    "\n",
    "# source: Mahdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out Dicky_Fuller test interpretations for each variable\n",
    "\n",
    "for col in cols_df:\n",
    "    test_stats = interpret_adftest(daily_df[col])\n",
    "    print(test_stats)\n",
    "    if test_stats[1] > 0.05:\n",
    "        print(f'{col} not stationary')\n",
    "    else:\n",
    "        print(f'{col} stationary')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All parameters are stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VAR Model**<br>\n",
    "Small dataset ==> no train-test split for trainig the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params15 = params.drop(columns=['Parameter_TURB_NTU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params15_monthly = params15.resample('M', closed='right', convention='end').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params15_monthly.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params15_monthly.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VAR model\n",
    "var = VAR(params15_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store fitted model in variable fitted_var\n",
    "# use Akaike information Criterion (aic)\n",
    "# trend = 'c' ==> add constant\n",
    "\n",
    "\n",
    "fitted_var = var.fit(maxlags=5, ic='aic', trend='c', verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_var.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_var.plot();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate the model = split the dataset into a 'training' and a 'testing' set (0.8 - 0.2 split)\n",
    "split_point = int(params15_monthly.shape[0] * 0.8)\n",
    "train = params15_monthly[:split_point]\n",
    "test = params15_monthly[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahdi's code\n",
    "# get predictions and confidence intervals for \"test\" set\n",
    "test_preds, lower_conf_ints, upper_conf_ints = fitted_var.forecast_interval(train.values, len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_conf_ints[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahdi's code\n",
    "# plot forecast\n",
    "fig, axes = plt.subplots(figsize=(12,30), nrows = 15)\n",
    "\n",
    "for i in range(15):\n",
    "    col_name = cols[i]\n",
    "    ax = axes[i]\n",
    "    \n",
    "    ax.set_title(col_name)\n",
    "    \n",
    "    train_col      = train[col_name] # pulling from pandas dataframe\n",
    "    test_col       = test[col_name]  # pulling from pandas dataframe\n",
    "    test_preds_col = test_preds[:,i] # pulling from numpy aray\n",
    "    lower_conf_int = lower_conf_ints[:,i] # pulling from numpy aray\n",
    "    upper_conf_int = upper_conf_ints[:,i] # pulling from numpy aray\n",
    "    \n",
    "    # Setting min and max (cuts off extreme conf. ints.)\n",
    "    max_val = max([max(train_col), max(test_col)])\n",
    "    min_val = min([min(train_col), min(test_col)])\n",
    "    diff = max_val - min_val\n",
    "    max_y = max_val + diff * 0.1\n",
    "    min_y = min_val - diff * 0.1\n",
    "    \n",
    "    # setting min and max y limits (due to extreme conf. ints.)\n",
    "    ax.set_ylim(ymin = min_y, ymax = max_y)\n",
    "    \n",
    "    # train data\n",
    "    ax.plot(train.index, train_col, lw=1, color='green', ls='solid',label='Train Data')\n",
    "\n",
    "    # test data\n",
    "    ax.plot(test.index, test_col, lw=1, color='blue', ls='solid',label='Test Data')\n",
    "\n",
    "    # forecast data\n",
    "    ax.plot(test.index, test_preds_col, lw=1, color='red', ls=\"solid\",  label='In-sample Predictions')\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(col_name)\n",
    "\n",
    "    # conf ints\n",
    "    ax.fill_between(test.index, lower_conf_int, upper_conf_int, color='k', alpha=0.1, label = \"95% Conf. Int.\");\n",
    "    ax.legend(loc = \"upper left\")\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** At this point the model does not predict well TP (total phosphorus). The in-data forecast approximates the test data well. However, I do not know how to interpret that both the forecast and the actual data points are outside the confidence interval. ==> __check what is going on__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahdi's code\n",
    "\n",
    "# getting first column of predictions (Chlorophyll)\n",
    "CHLA_preds = test_preds[:,0]\n",
    "CHLA_true = test.iloc[:,0]\n",
    "print('Clorophyll')\n",
    "print('R2 score:', round(r2_score(CHLA_preds, CHLA_true), 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting 13th column of predictions (Total Phosphorus)\n",
    "TP_preds = test_preds[:,12]\n",
    "TP_true = test.iloc[:,12]\n",
    "print('Total Phosphorus')\n",
    "print('R2 score:', round(r2_score(TP_preds, TP_true), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
